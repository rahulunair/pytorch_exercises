{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn \n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "lr = 1e-6\n",
    "EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random input , target and weights\n",
    "x = Variable(torch.randn(N, D_in), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "w1, w2 = Variable(torch.randn(D_in, H), requires_grad=True), Variable(torch.randn(H, D_out), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 577.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193, Squared Error: 9.75530433655\n",
      "Epoch: 194, Squared Error: 9.33067798615\n",
      "Epoch: 195, Squared Error: 8.92428779602\n",
      "Epoch: 196, Squared Error: 8.53660488129\n",
      "Epoch: 197, Squared Error: 8.16599845886\n",
      "Epoch: 198, Squared Error: 7.81162643433\n",
      "Epoch: 199, Squared Error: 7.47278022766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# manual NN\n",
    "for t in tqdm(range(EPOCH)):\n",
    "    #forward passs\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t > EPOCH * 0.96:\n",
    "        print (\"Epoch: {}, Squared Error: {}\".format(t, loss.data[0]))\n",
    "    #automatic backprop\n",
    "    loss.backward()\n",
    "    w1.data -= lr * w1.grad.data\n",
    "    w2.data -= lr * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn module\n",
    "model = nn.Sequential(nn.Linear(D_in, H),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(H, D_out))\n",
    "loss_function = nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 491, Squared Error: 7.18568435332e-06\n",
      "Epoch: 492, Squared Error: 6.99095471646e-06\n",
      "Epoch: 493, Squared Error: 6.80142784404e-06\n",
      "Epoch: 494, Squared Error: 6.61750891595e-06\n",
      "Epoch: 495, Squared Error: 6.43914290777e-06\n",
      "Epoch: 496, Squared Error: 6.26421569905e-06\n",
      "Epoch: 497, Squared Error: 6.09577773503e-06\n",
      "Epoch: 498, Squared Error: 5.93052754994e-06\n",
      "Epoch: 499, Squared Error: 5.77082073505e-06\n",
      "Yay!!, Done!\n"
     ]
    }
   ],
   "source": [
    "# Random input , target and weights\n",
    "x = Variable(torch.randn(N, D_in), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "lr = 1e-4\n",
    "for t in range(EPOCH):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "    \n",
    "    model.zero_grad()  # reset gradient\n",
    "    loss.backward()  #backprop\n",
    "    if t > EPOCH * 0.98:\n",
    "        print (\"Epoch: {}, Squared Error: {}\".format(t, loss.data[0]))\n",
    "    for p in model.parameters():\n",
    "        p.data -= lr *p.grad.data\n",
    "print(\"Yay!!, Done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random input and target data\n",
    "x = Variable(torch.randn(N, D_in), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using ADAM optimizer\n",
    "model = nn.Sequential(nn.Linear(D_in, H),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(H, D_out))\n",
    "loss_fn = nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 338.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 491, Squared Error: 8.06809021014e-06\n",
      "Epoch: 492, Squared Error: 7.69934922573e-06\n",
      "Epoch: 493, Squared Error: 7.34719742468e-06\n",
      "Epoch: 494, Squared Error: 7.01082353771e-06\n",
      "Epoch: 495, Squared Error: 6.6897182478e-06\n",
      "Epoch: 496, Squared Error: 6.38247956886e-06\n",
      "Epoch: 497, Squared Error: 6.08786695011e-06\n",
      "Epoch: 498, Squared Error: 5.80704636377e-06\n",
      "Epoch: 499, Squared Error: 5.53961581318e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's run through all the EPOCH\n",
    "for t in tqdm(range(EPOCH)):\n",
    "    #feed forward\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t > EPOCH * 0.98:\n",
    "        print (\"Epoch: {}, Squared Error: {}\".format(t, loss.data[0]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets create our on custom NN model \n",
    "class Runet(nn.Module):\n",
    "    \"\"\" A custom Neural Net with 3 hidden Sequential layers\"\"\"\n",
    "    \n",
    "    def __init__(self,D_in, H1, H2, H3, D_out):\n",
    "        super(Runet, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, H3)\n",
    "        self.linear4 = nn.Linear(H3, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Feed foward part, where we describe how the NNet is\n",
    "           connected and feed the input data\n",
    "        \"\"\"\n",
    "        h1_relu = self.linear1(x).clamp(min=0)\n",
    "        h2 = self.linear2(h1_relu)\n",
    "        h3 = self.linear3(h2)\n",
    "        y_pred = self.linear4(h3)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions and Hyperparameters of the Neural Net\n",
    "N, D_in, H1, H2, H3, D_out = 64, 1000, 100, 100, 100, 10\n",
    "lr = 1e-4\n",
    "EPOCH=500\n",
    "\n",
    "# Random Input and Target values\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "X = Variable(x, requires_grad=False)\n",
    "Y = Variable(y, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Runet(D_in, H1, H2, H3, D_out)\n",
    "loss_fn = nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 259.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 295 and LOSS 0.0123166963458\n",
      "EPOCH 296 and LOSS 0.0134867755696\n",
      "EPOCH 297 and LOSS 0.0123318349943\n",
      "EPOCH 298 and LOSS 0.00936056207865\n",
      "EPOCH 299 and LOSS 0.0104877706617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets run through all EPOCHS\n",
    "for t in tqdm(range(EPOCH)):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    if t > EPOCH * 0.98 :\n",
    "        print(\"EPOCH {} and LOSS {}\".format(t, loss.data[0]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Model with weight sharing\n",
    "import random\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    \"\"\"Dynamic Network, where there can be\n",
    "    n - number of hidden layers.\"\"\"\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(DNet, self).__init__()\n",
    "        self.input = nn.Linear(D_in, H)\n",
    "        self.hidden = nn.Linear(H, H)\n",
    "        self.output = nn.Linear(H, D_out)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        h_relu = self.input(X).clamp(min=0)\n",
    "        for h_layers in range(random.randint(1, 3)):\n",
    "            h_relu = self.hidden(h_relu)\n",
    "        h_relu = self.output(h_relu)\n",
    "        return h_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dimensions and Hyperparameters of the Neural Net\n",
    "N, D_in, H1, H2, H3, D_out = 64, 1000, 100, 100, 100, 10\n",
    "lr = 1e-4\n",
    "EPOCH=500\n",
    "\n",
    "# Random Input and Target values\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "X = Variable(x, requires_grad=False)\n",
    "Y = Variable(y, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = DNet(D_in, H1, D_out)\n",
    "loss_fn = nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 279.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 496 SQUARED ERROR: 218.35949707\n",
      "EPOCH: 497 SQUARED ERROR: 216.605056763\n",
      "EPOCH: 498 SQUARED ERROR: 215.079040527\n",
      "EPOCH: 499 SQUARED ERROR: 254.739318848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(EPOCH)):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    if t > EPOCH * 0.99:\n",
    "        print(\"EPOCH: {} SQUARED ERROR: {}\".format(t, loss.data[0]))\n",
    "    optmizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/rahul'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 68\r\n",
      "drwxrwxr-x 20 rahul  4096 Jun 22 10:04 \u001b[0m\u001b[01;34manaconda3\u001b[0m/\r\n",
      "drwxrwxr-x  5 rahul  4096 Jul 14 15:07 \u001b[01;34mCoding\u001b[0m/\r\n",
      "drwxr-xr-x  3 rahul  4096 Jul 14 11:25 \u001b[01;34mDesktop\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mDocuments\u001b[0m/\r\n",
      "drwxr-xr-x  3 rahul  4096 Jul 12 09:55 \u001b[01;34mDownloads\u001b[0m/\r\n",
      "drwxrwxr-x 10 rahul  4096 Jul  7 16:35 \u001b[01;34mgym\u001b[0m/\r\n",
      "drwxrwxr-x  6 rahul  4096 Jun 29 11:12 \u001b[01;34mmachineLearning\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mMusic\u001b[0m/\r\n",
      "drwxrwxr-x  2 rahul  4096 Jul 14 11:06 \u001b[01;34mNotebooks\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mPictures\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mPublic\u001b[0m/\r\n",
      "-rw-rw-r--  1 rahul 12047 Jul 18 13:51 pytorch_basics.ipynb\r\n",
      "drwxrwxr-x  2 rahul  4096 Jun  6 16:41 \u001b[01;34mscikit_learn_data\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mTemplates\u001b[0m/\r\n",
      "drwxr-xr-x  2 rahul  4096 Jun  5 16:21 \u001b[01;34mVideos\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scp"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
